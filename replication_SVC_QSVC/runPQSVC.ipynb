{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61fbb198-d94b-4161-bcca-b210a937ae85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "# from qiskit_machine_learning.algorithms import PegasosQSVC, QSVC\n",
    "# from qiskit_machine_learning.kernels import FidelityQuantumKernel\n",
    "#from qiskit.circuit.library import ZFeatureMap\n",
    "#from qiskit_algorithms.utils import algorithm_globals\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from custom_functions import print_result, getQAlgo, aggregate_pred, weighted_average, read_df, my_round, run_classical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "415d75da-b77c-431f-937f-c7c209d65da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_time testing_time accuracy, precision, recall, f1, roc_auc, mcc\n",
    "# dataset_names = ['jm1', 'camel', 'os', 'bitcoin', 'qt', 'jenkins', 'litecoin',  'mongo', 'zxing', \n",
    "#                  'jackrabbit', 'oozie', 'tomcat', 'lucene', 'ambari', 'accumulo']\n",
    "\n",
    "class_file_names = ['futile_abstract_pipeline', 'god_class', 'futile_hierarchy', 'model_class', \n",
    "                    'brain_class', 'data_class', 'schizofrenic_class']\n",
    "method_file_names = ['shortcircuiting_method', 'brain_method', 'shotgun_surgery', 'extensive_coupling', \n",
    "                     'feature_envy', 'intensive_coupling']\n",
    "\n",
    "# print(len(dataset_names), dataset_names[6:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba018a23-48a9-40b9-9a0b-8abd83b76dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (7452, 10) Counter({0: 3736, 1: 3716})\n",
      "test: (3194, 10) Counter({1: 1607, 0: 1587})\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1537   50]\n",
      " [  29 1578]]\n",
      "[0.98, 0.97, 0.98, 0.98, 0.98, 0.95]\n",
      "shortcircuiting_method: experiment time for dataset size 7452: 0.7 seconds\n",
      "----------------------------------\n",
      "train: (21392, 10) Counter({0: 10747, 1: 10645})\n",
      "test: (9168, 10) Counter({1: 4635, 0: 4533})\n",
      "\n",
      "Confusion Matrix:\n",
      " [[4470   63]\n",
      " [   0 4635]]\n",
      "[0.99, 0.99, 1.0, 0.99, 0.99, 0.99]\n",
      "brain_method: experiment time for dataset size 21392: 1.21 seconds\n",
      "----------------------------------\n",
      "train: (27501, 10) Counter({1: 13759, 0: 13742})\n",
      "test: (11787, 10) Counter({0: 5902, 1: 5885})\n",
      "\n",
      "Confusion Matrix:\n",
      " [[5788  114]\n",
      " [  12 5873]]\n",
      "[0.99, 0.98, 1.0, 0.99, 0.99, 0.98]\n",
      "shotgun_surgery: experiment time for dataset size 27501: 3.43 seconds\n",
      "----------------------------------\n",
      "train: (4368, 10) Counter({1: 2191, 0: 2177})\n",
      "test: (1872, 10) Counter({0: 943, 1: 929})\n",
      "\n",
      "Confusion Matrix:\n",
      " [[933  10]\n",
      " [  0 929]]\n",
      "[0.99, 0.99, 1.0, 0.99, 0.99, 0.99]\n",
      "extensive_coupling: experiment time for dataset size 4368: 0.06 seconds\n",
      "----------------------------------\n",
      "train: (31392, 10) Counter({0: 15713, 1: 15679})\n",
      "test: (13454, 10) Counter({1: 6744, 0: 6710})\n",
      "\n",
      "Confusion Matrix:\n",
      " [[6653   57]\n",
      " [   0 6744]]\n",
      "[1.0, 0.99, 1.0, 1.0, 1.0, 0.99]\n",
      "feature_envy: experiment time for dataset size 31392: 2.4 seconds\n",
      "----------------------------------\n",
      "train: (11320, 10) Counter({0: 5675, 1: 5645})\n",
      "test: (4852, 10) Counter({1: 2441, 0: 2411})\n",
      "\n",
      "Confusion Matrix:\n",
      " [[2382   29]\n",
      " [   1 2440]]\n",
      "[0.99, 0.99, 1.0, 0.99, 0.99, 0.99]\n",
      "intensive_coupling: experiment time for dataset size 11320: 0.41 seconds\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "data_type = 'method'\n",
    "data_dir = \"../datasets/codesmell/\"\n",
    "for file in method_file_names:\n",
    "    trainX, trainY = read_df(f\"{data_dir}{data_type}_balanced/{file}_train.csv\")\n",
    "    print(\"train:\", trainX.shape, Counter(trainY))\n",
    "    \n",
    "    testX, testY = read_df(f\"{data_dir}{data_type}_balanced/{file}_test.csv\")\n",
    "    print(\"test:\", testX.shape, Counter(testY))\n",
    "    print()\n",
    "    \n",
    "    trainF = np.array(trainX, dtype='float')\n",
    "    testF = np.array(testX, dtype='float')\n",
    "\n",
    "    st = time.time()        \n",
    "    # run_classical(getQAlgo('pqsvc'), \n",
    "    #           np.array(trainX, dtype='float'), \n",
    "    #           trainY, \n",
    "    #           np.array(testX, dtype='float'), \n",
    "    #           testY)\n",
    "    run_classical(make_pipeline(StandardScaler(), SVC(gamma='auto')), trainF, trainY, testF, testY)\n",
    "    et = time.time()\n",
    "    print('{}: experiment time for dataset size {}: {} seconds'.format(file, len(trainX), round(et - st, 2)))\n",
    "    print('----------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7b833f-afcf-424b-97e7-54e2fde23854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jm1\n",
      "(3369, 10) (3369,) (843, 10) (843,)\n",
      "Confusion Matrix:\n",
      " [[326  87]\n",
      " [199 231]]\n",
      "[0.66, 0.73, 0.54, 0.62, 0.66, 0.34]\n",
      "jm1: experiment time for dataset size 3369: 0.51 seconds\n",
      "----------------------------------\n",
      "camel\n",
      "(928, 10) (928,) (400, 10) (400,)\n",
      "Confusion Matrix:\n",
      " [[167  33]\n",
      " [ 36 164]]\n",
      "[0.83, 0.83, 0.82, 0.83, 0.83, 0.66]\n",
      "camel: experiment time for dataset size 928: 0.05 seconds\n",
      "----------------------------------\n",
      "os\n",
      "(936, 10) (936,) (404, 10) (404,)\n",
      "Confusion Matrix:\n",
      " [[100 102]\n",
      " [153  49]]\n",
      "[0.37, 0.32, 0.24, 0.28, 0.37, -0.27]\n",
      "os: experiment time for dataset size 936: 0.06 seconds\n",
      "----------------------------------\n",
      "bitcoin\n",
      "(460, 10) (460,) (200, 10) (200,)\n",
      "Confusion Matrix:\n",
      " [[85 15]\n",
      " [22 78]]\n",
      "[0.81, 0.84, 0.78, 0.81, 0.82, 0.63]\n",
      "bitcoin: experiment time for dataset size 460: 0.02 seconds\n",
      "----------------------------------\n",
      "qt\n",
      "(472, 10) (472,) (204, 10) (204,)\n",
      "Confusion Matrix:\n",
      " [[89 13]\n",
      " [50 52]]\n",
      "[0.69, 0.8, 0.51, 0.62, 0.69, 0.41]\n",
      "qt: experiment time for dataset size 472: 0.02 seconds\n",
      "----------------------------------\n",
      "jenkins\n",
      "(444, 10) (444,) (192, 10) (192,)\n",
      "Confusion Matrix:\n",
      " [[83 13]\n",
      " [24 72]]\n",
      "[0.81, 0.85, 0.75, 0.8, 0.81, 0.62]\n",
      "jenkins: experiment time for dataset size 444: 0.02 seconds\n",
      "----------------------------------\n",
      "litecoin\n",
      "(442, 10) (442,) (192, 10) (192,)\n",
      "Confusion Matrix:\n",
      " [[77 19]\n",
      " [23 73]]\n",
      "[0.78, 0.79, 0.76, 0.78, 0.78, 0.56]\n",
      "litecoin: experiment time for dataset size 442: 0.02 seconds\n",
      "----------------------------------\n",
      "mongo\n",
      "(368, 10) (368,) (158, 10) (158,)\n",
      "Confusion Matrix:\n",
      " [[63 16]\n",
      " [21 58]]\n",
      "[0.77, 0.78, 0.73, 0.76, 0.77, 0.53]\n",
      "mongo: experiment time for dataset size 368: 0.02 seconds\n",
      "----------------------------------\n",
      "zxing\n",
      "(508, 10) (508,) (218, 10) (218,)\n",
      "Confusion Matrix:\n",
      " [[78 31]\n",
      " [23 86]]\n",
      "[0.75, 0.74, 0.79, 0.76, 0.75, 0.51]\n",
      "zxing: experiment time for dataset size 508: 0.02 seconds\n",
      "----------------------------------\n",
      "jackrabbit\n",
      "(556, 10) (556,) (240, 10) (240,)\n",
      "Confusion Matrix:\n",
      " [[94 26]\n",
      " [28 92]]\n",
      "[0.78, 0.78, 0.77, 0.77, 0.77, 0.55]\n",
      "jackrabbit: experiment time for dataset size 556: 0.02 seconds\n",
      "----------------------------------\n",
      "oozie\n",
      "(358, 10) (358,) (156, 10) (156,)\n",
      "Confusion Matrix:\n",
      " [[62 16]\n",
      " [19 59]]\n",
      "[0.78, 0.79, 0.76, 0.77, 0.78, 0.55]\n",
      "oozie: experiment time for dataset size 358: 0.02 seconds\n",
      "----------------------------------\n",
      "tomcat\n",
      "(452, 10) (452,) (194, 10) (194,)\n",
      "Confusion Matrix:\n",
      " [[48 49]\n",
      " [22 75]]\n",
      "[0.63, 0.6, 0.77, 0.68, 0.63, 0.28]\n",
      "tomcat: experiment time for dataset size 452: 0.02 seconds\n",
      "----------------------------------\n",
      "lucene\n",
      "(348, 10) (348,) (150, 10) (150,)\n",
      "Confusion Matrix:\n",
      " [[61 14]\n",
      " [28 47]]\n",
      "[0.72, 0.77, 0.63, 0.69, 0.72, 0.45]\n",
      "lucene: experiment time for dataset size 348: 0.02 seconds\n",
      "----------------------------------\n",
      "ambari\n",
      "(410, 10) (410,) (178, 10) (178,)\n",
      "Confusion Matrix:\n",
      " [[72 17]\n",
      " [40 49]]\n",
      "[0.68, 0.74, 0.55, 0.63, 0.68, 0.37]\n",
      "ambari: experiment time for dataset size 410: 0.02 seconds\n",
      "----------------------------------\n",
      "accumulo\n",
      "(284, 10) (284,) (122, 10) (122,)\n",
      "Confusion Matrix:\n",
      " [[48 13]\n",
      " [18 43]]\n",
      "[0.75, 0.77, 0.7, 0.74, 0.75, 0.49]\n",
      "accumulo: experiment time for dataset size 284: 0.01 seconds\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"datasets/balanced/\"\n",
    "for filename in dataset_names:  \n",
    "    print(filename)\n",
    "    trainX, trainY = read_df(data_dir + 'b_'+filename+'_train.csv')\n",
    "    testX, testY = read_df(data_dir + 'b_'+filename+'_test.csv')\n",
    "    print(trainX.shape, trainY.shape, testX.shape, testY.shape)\n",
    "    \n",
    "    trainF = np.array(trainX, dtype='float')\n",
    "    testF = np.array(testX, dtype='float')\n",
    "\n",
    "    st = time.time()        \n",
    "    # run_classical(getQAlgo('pqsvc'), \n",
    "    #           np.array(trainX, dtype='float'), \n",
    "    #           trainY, \n",
    "    #           np.array(testX, dtype='float'), \n",
    "    #           testY)\n",
    "    run_classical(make_pipeline(StandardScaler(), SVC(gamma='auto')), trainF, trainY, testF, testY)\n",
    "    et = time.time()\n",
    "    print('{}: experiment time for dataset size {}: {} seconds'.format(filename, len(trainX), round(et - st, 2)))\n",
    "    print('----------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
